{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for ffmpeg installation...\n",
      "✓ Found working ffmpeg at: /usr/bin/ffmpeg\n",
      "\n",
      "📅 Searching for tracks from 2024-07-01 to 2024-07-02\n",
      "📁 Output directory: soundcloud_downloads\n",
      "\n",
      "Found 2 potential tracks to download\n",
      "\n",
      "[1/2] Processing 2024-07-01\n",
      "⬇ Downloading: https://soundcloud.com/radio-ergo/idaacadda-01-jul-2024\n",
      "  Using ffmpeg from: /usr/bin\n",
      "✓ Successfully downloaded: IDAACADDA 01-JUL-2024.mp3                      \n",
      "[2/2] Processing 2024-07-02\n",
      "⬇ Downloading: https://soundcloud.com/radio-ergo/idaacadda-02-jul-2024\n",
      "  Using ffmpeg from: /usr/bin\n",
      "✓ Successfully downloaded: IDAACADDA 02-JUL-2024.mp3                      \n",
      "\n",
      "==================================================\n",
      "Download Summary:\n",
      "  ✓ Successful: 2\n",
      "  ✗ Failed: 0\n",
      "  📁 Files saved to: soundcloud_downloads\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "SoundCloud Downloader for Linux - Fixed FFmpeg Integration\n",
    "Properly handles ffmpeg path detection and passing to yt-dlp\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import re\n",
    "import subprocess\n",
    "import sys\n",
    "from datetime import datetime, timedelta\n",
    "import yt_dlp\n",
    "import requests\n",
    "import time\n",
    "import hashlib\n",
    "import json\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "class SoundCloudDownloader:\n",
    "    def __init__(self, output_dir=\"downloads\"):\n",
    "        self.output_dir = output_dir\n",
    "        self.ffmpeg_path = None\n",
    "        self.download_log = {}\n",
    "        self.log_file = os.path.join(output_dir, \".download_log.json\")\n",
    "        \n",
    "        # Create output directory if it doesn't exist\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        # Load download log\n",
    "        self.load_download_log()\n",
    "        \n",
    "        # Setup ffmpeg on initialization\n",
    "        self.setup_ffmpeg()\n",
    "    \n",
    "    def load_download_log(self):\n",
    "        \"\"\"Load the download log from file.\"\"\"\n",
    "        if os.path.exists(self.log_file):\n",
    "            try:\n",
    "                with open(self.log_file, 'r') as f:\n",
    "                    self.download_log = json.load(f)\n",
    "            except:\n",
    "                self.download_log = {}\n",
    "    \n",
    "    def save_download_log(self):\n",
    "        \"\"\"Save the download log to file.\"\"\"\n",
    "        try:\n",
    "            with open(self.log_file, 'w') as f:\n",
    "                json.dump(self.download_log, f, indent=2)\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Could not save download log: {e}\")\n",
    "    \n",
    "    def find_ffmpeg(self):\n",
    "        \"\"\"Find ffmpeg binary in system.\"\"\"\n",
    "        # Check if ffmpeg is in PATH using shutil.which\n",
    "        ffmpeg_in_path = shutil.which('ffmpeg')\n",
    "        if ffmpeg_in_path:\n",
    "            return ffmpeg_in_path\n",
    "        \n",
    "        # Common locations to check\n",
    "        common_locations = [\n",
    "            '/usr/bin/ffmpeg',\n",
    "            '/usr/local/bin/ffmpeg',\n",
    "            '/opt/homebrew/bin/ffmpeg',\n",
    "            '/snap/bin/ffmpeg',\n",
    "            '~/.local/bin/ffmpeg',\n",
    "        ]\n",
    "        \n",
    "        for location in common_locations:\n",
    "            expanded_path = os.path.expanduser(location)\n",
    "            if os.path.exists(expanded_path) and os.access(expanded_path, os.X_OK):\n",
    "                return expanded_path\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def setup_ffmpeg(self):\n",
    "        \"\"\"Setup ffmpeg for Linux systems - improved detection.\"\"\"\n",
    "        print(\"Checking for ffmpeg installation...\")\n",
    "        \n",
    "        # First try to find existing ffmpeg\n",
    "        self.ffmpeg_path = self.find_ffmpeg()\n",
    "        \n",
    "        if self.ffmpeg_path:\n",
    "            # Verify it actually works\n",
    "            if self.verify_ffmpeg(self.ffmpeg_path):\n",
    "                print(f\"✓ Found working ffmpeg at: {self.ffmpeg_path}\")\n",
    "                return True\n",
    "            else:\n",
    "                print(f\"⚠ Found ffmpeg at {self.ffmpeg_path} but it doesn't work properly\")\n",
    "                self.ffmpeg_path = None\n",
    "        \n",
    "        # If not found, try to install it\n",
    "        print(\"ffmpeg not found. Attempting to install...\")\n",
    "        \n",
    "        if self.install_ffmpeg():\n",
    "            # Re-check after installation\n",
    "            self.ffmpeg_path = self.find_ffmpeg()\n",
    "            if self.ffmpeg_path and self.verify_ffmpeg(self.ffmpeg_path):\n",
    "                print(f\"✓ Successfully installed ffmpeg at: {self.ffmpeg_path}\")\n",
    "                return True\n",
    "        \n",
    "        print(\"⚠ Failed to install ffmpeg automatically.\")\n",
    "        print(\"Please install it manually:\")\n",
    "        print(\"  Ubuntu/Debian: sudo apt-get install ffmpeg\")\n",
    "        print(\"  Fedora: sudo dnf install ffmpeg\")\n",
    "        print(\"  Arch: sudo pacman -S ffmpeg\")\n",
    "        return False\n",
    "    \n",
    "    def verify_ffmpeg(self, ffmpeg_path):\n",
    "        \"\"\"Verify that ffmpeg actually works.\"\"\"\n",
    "        try:\n",
    "            result = subprocess.run(\n",
    "                [ffmpeg_path, '-version'],\n",
    "                capture_output=True,\n",
    "                text=True,\n",
    "                timeout=5\n",
    "            )\n",
    "            return result.returncode == 0 and 'ffmpeg version' in result.stdout\n",
    "        except Exception as e:\n",
    "            print(f\"Error verifying ffmpeg: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def install_ffmpeg(self):\n",
    "        \"\"\"Try to install ffmpeg based on detected OS.\"\"\"\n",
    "        try:\n",
    "            # Detect the Linux distribution\n",
    "            if os.path.exists('/etc/os-release'):\n",
    "                with open('/etc/os-release', 'r') as f:\n",
    "                    os_info = f.read().lower()\n",
    "                \n",
    "                if 'ubuntu' in os_info or 'debian' in os_info:\n",
    "                    print(\"Installing ffmpeg using apt...\")\n",
    "                    subprocess.run(['sudo', 'apt-get', 'update'], check=False, capture_output=True)\n",
    "                    result = subprocess.run(['sudo', 'apt-get', 'install', '-y', 'ffmpeg'], \n",
    "                                          capture_output=True, text=True)\n",
    "                    return result.returncode == 0\n",
    "                    \n",
    "                elif 'fedora' in os_info:\n",
    "                    print(\"Installing ffmpeg using dnf...\")\n",
    "                    result = subprocess.run(['sudo', 'dnf', 'install', '-y', 'ffmpeg'], \n",
    "                                          capture_output=True, text=True)\n",
    "                    return result.returncode == 0\n",
    "                    \n",
    "                elif 'arch' in os_info:\n",
    "                    print(\"Installing ffmpeg using pacman...\")\n",
    "                    result = subprocess.run(['sudo', 'pacman', '-S', '--noconfirm', 'ffmpeg'], \n",
    "                                          capture_output=True, text=True)\n",
    "                    return result.returncode == 0\n",
    "        except Exception as e:\n",
    "            print(f\"Error during installation: {e}\")\n",
    "        \n",
    "        return False\n",
    "    \n",
    "    def validate_url(self, url):\n",
    "        \"\"\"Validate if the URL is a valid SoundCloud URL.\"\"\"\n",
    "        pattern = r'^https?://(?:www\\.)?soundcloud\\.com/[\\w-]+/[\\w-]+'\n",
    "        return bool(re.match(pattern, url))\n",
    "    \n",
    "    def get_file_hash(self, url):\n",
    "        \"\"\"Generate a unique hash for a URL.\"\"\"\n",
    "        return hashlib.md5(url.encode()).hexdigest()\n",
    "    \n",
    "    def is_already_downloaded(self, url):\n",
    "        \"\"\"Check if a URL has already been successfully downloaded.\"\"\"\n",
    "        url_hash = self.get_file_hash(url)\n",
    "        \n",
    "        if url_hash in self.download_log:\n",
    "            file_path = self.download_log[url_hash].get('file_path')\n",
    "            if file_path and os.path.exists(file_path):\n",
    "                file_size = os.path.getsize(file_path)\n",
    "                if file_size > 1000000:  # > 1MB\n",
    "                    print(f\"✓ Already downloaded: {os.path.basename(file_path)}\")\n",
    "                    return True\n",
    "        \n",
    "        return False\n",
    "    \n",
    "    def download_audio(self, url, max_retries=3):\n",
    "        \"\"\"Download audio from SoundCloud URL with proper ffmpeg configuration.\"\"\"\n",
    "        if not self.validate_url(url):\n",
    "            print(f\"✗ Invalid URL: {url}\")\n",
    "            return None\n",
    "        \n",
    "        # Check if already downloaded\n",
    "        if self.is_already_downloaded(url):\n",
    "            return self.download_log[self.get_file_hash(url)]['file_path']\n",
    "        \n",
    "        print(f\"⬇ Downloading: {url}\")\n",
    "        \n",
    "        # Configure yt-dlp options\n",
    "        ydl_opts = {\n",
    "            'format': 'bestaudio/best',\n",
    "            'outtmpl': os.path.join(self.output_dir, '%(title)s.%(ext)s'),\n",
    "            'noplaylist': True,\n",
    "            'quiet': True,\n",
    "            'no_warnings': True,\n",
    "            'retries': 10,\n",
    "            'fragment_retries': 10,\n",
    "            'skip_unavailable_fragments': True,\n",
    "            # Audio extraction settings\n",
    "            'postprocessors': [{\n",
    "                'key': 'FFmpegExtractAudio',\n",
    "                'preferredcodec': 'mp3',\n",
    "                'preferredquality': '192',\n",
    "            }],\n",
    "            'prefer_ffmpeg': True,  # Prefer ffmpeg over avconv\n",
    "        }\n",
    "        \n",
    "        # CRITICAL: Set ffmpeg location properly\n",
    "        if self.ffmpeg_path:\n",
    "            # Get the directory containing ffmpeg\n",
    "            ffmpeg_dir = os.path.dirname(self.ffmpeg_path)\n",
    "            ydl_opts['ffmpeg_location'] = ffmpeg_dir\n",
    "            print(f\"  Using ffmpeg from: {ffmpeg_dir}\")\n",
    "        \n",
    "        # Try downloading with retries\n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "                    # Extract info first\n",
    "                    info = ydl.extract_info(url, download=False)\n",
    "                    \n",
    "                    # Generate expected filename\n",
    "                    filename = ydl.prepare_filename(info)\n",
    "                    base, _ = os.path.splitext(filename)\n",
    "                    mp3_file = f\"{base}.mp3\"\n",
    "                    \n",
    "                    # Check if file already exists\n",
    "                    if os.path.exists(mp3_file) and os.path.getsize(mp3_file) > 1000000:\n",
    "                        print(f\"✓ File already exists: {os.path.basename(mp3_file)}\")\n",
    "                        # Add to log\n",
    "                        self.download_log[self.get_file_hash(url)] = {\n",
    "                            'url': url,\n",
    "                            'file_path': mp3_file,\n",
    "                            'download_date': datetime.now().isoformat()\n",
    "                        }\n",
    "                        self.save_download_log()\n",
    "                        return mp3_file\n",
    "                    \n",
    "                    # Now download\n",
    "                    ydl.download([url])\n",
    "                    \n",
    "                    # Verify the download\n",
    "                    if os.path.exists(mp3_file) and os.path.getsize(mp3_file) > 0:\n",
    "                        print(f\"✓ Successfully downloaded: {os.path.basename(mp3_file)}\")\n",
    "                        \n",
    "                        # Add to download log\n",
    "                        self.download_log[self.get_file_hash(url)] = {\n",
    "                            'url': url,\n",
    "                            'file_path': mp3_file,\n",
    "                            'download_date': datetime.now().isoformat()\n",
    "                        }\n",
    "                        self.save_download_log()\n",
    "                        \n",
    "                        return mp3_file\n",
    "                    else:\n",
    "                        raise Exception(\"Downloaded file is empty or missing\")\n",
    "                        \n",
    "            except Exception as e:\n",
    "                error_msg = str(e)[:100]\n",
    "                print(f\"  Attempt {attempt + 1}/{max_retries} failed: {error_msg}\")\n",
    "                \n",
    "                # If ffmpeg issue, try to fix it\n",
    "                if 'ffmpeg' in error_msg.lower() and attempt == 0:\n",
    "                    print(\"  Attempting to fix ffmpeg configuration...\")\n",
    "                    self.setup_ffmpeg()\n",
    "                \n",
    "                if attempt < max_retries - 1:\n",
    "                    time.sleep(5 * (attempt + 1))\n",
    "        \n",
    "        print(f\"✗ Failed to download after {max_retries} attempts\")\n",
    "        return None\n",
    "    \n",
    "    def download_date_range(self, profile_url, start_date, end_date):\n",
    "        \"\"\"\n",
    "        Download tracks from a SoundCloud profile within a date range.\n",
    "        \n",
    "        Args:\n",
    "            profile_url: SoundCloud profile URL\n",
    "            start_date: Start date (datetime object or string 'YYYY-MM-DD')\n",
    "            end_date: End date (datetime object or string 'YYYY-MM-DD')\n",
    "        \n",
    "        Returns:\n",
    "            Tuple of (successful_downloads, failed_urls)\n",
    "        \"\"\"\n",
    "        # Parse dates if strings\n",
    "        if isinstance(start_date, str):\n",
    "            start_date = datetime.strptime(start_date, '%Y-%m-%d')\n",
    "        if isinstance(end_date, str):\n",
    "            end_date = datetime.strptime(end_date, '%Y-%m-%d')\n",
    "        \n",
    "        print(f\"\\n📅 Searching for tracks from {start_date.date()} to {end_date.date()}\")\n",
    "        print(f\"📁 Output directory: {self.output_dir}\\n\")\n",
    "        \n",
    "        # Generate URLs for date range\n",
    "        urls = self.generate_urls_for_range(profile_url, start_date, end_date)\n",
    "        \n",
    "        if not urls:\n",
    "            print(\"No URLs found for the specified date range\")\n",
    "            return [], []\n",
    "        \n",
    "        print(f\"Found {len(urls)} potential tracks to download\\n\")\n",
    "        \n",
    "        successful = []\n",
    "        failed = []\n",
    "        \n",
    "        for i, (date, url) in enumerate(urls, 1):\n",
    "            print(f\"[{i}/{len(urls)}] Processing {date.date()}\")\n",
    "            \n",
    "            # Check if URL exists (optional - can be skipped for faster processing)\n",
    "            try:\n",
    "                response = requests.head(url, timeout=5, allow_redirects=True)\n",
    "                if response.status_code == 404:\n",
    "                    print(f\"  ✗ URL not found (404)\")\n",
    "                    failed.append(url)\n",
    "                    continue\n",
    "            except:\n",
    "                pass  # Try downloading anyway\n",
    "            \n",
    "            result = self.download_audio(url)\n",
    "            \n",
    "            if result:\n",
    "                successful.append(result)\n",
    "            else:\n",
    "                failed.append(url)\n",
    "            \n",
    "            # Small delay between downloads\n",
    "            if i < len(urls):\n",
    "                time.sleep(2)\n",
    "        \n",
    "        # Print summary\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"Download Summary:\")\n",
    "        print(f\"  ✓ Successful: {len(successful)}\")\n",
    "        print(f\"  ✗ Failed: {len(failed)}\")\n",
    "        print(f\"  📁 Files saved to: {self.output_dir}\")\n",
    "        print(f\"{'='*50}\\n\")\n",
    "        \n",
    "        return successful, failed\n",
    "    \n",
    "    def generate_urls_for_range(self, profile_url, start_date, end_date):\n",
    "        \"\"\"Generate potential URLs for a date range.\"\"\"\n",
    "        urls = []\n",
    "        \n",
    "        # Clean profile URL\n",
    "        profile_url = profile_url.rstrip('/')\n",
    "        \n",
    "        current_date = start_date\n",
    "        while current_date <= end_date:\n",
    "            day = current_date.day\n",
    "            month = current_date.strftime('%b').lower()\n",
    "            year = current_date.year\n",
    "            \n",
    "            # Generate potential URL formats (most common first)\n",
    "            potential_urls = [\n",
    "                f\"{profile_url}/idaacadda-{day:02d}-{month}-{year}\",\n",
    "                f\"{profile_url}/idaacadda-{day}-{month}-{year}\",\n",
    "            ]\n",
    "            \n",
    "            # Add the first URL for this date\n",
    "            urls.append((current_date, potential_urls[0]))\n",
    "            \n",
    "            current_date += timedelta(days=1)\n",
    "        \n",
    "        return urls\n",
    "\n",
    "\n",
    "# Usage example\n",
    "def main():\n",
    "    \"\"\"Main function for command-line usage.\"\"\"\n",
    "    downloader = SoundCloudDownloader(output_dir=\"data\")\n",
    "    \n",
    "    # Download a specific date range\n",
    "    profile_url = \"https://soundcloud.com/radio-ergo\"\n",
    "    start_date = \"2024-07-01\"\n",
    "    end_date = \"2024-07-02\"\n",
    "    \n",
    "    successful, failed = downloader.download_date_range(\n",
    "        profile_url,\n",
    "        start_date,\n",
    "        end_date\n",
    "    )\n",
    "    \n",
    "    # Retry failed downloads if any\n",
    "    if failed:\n",
    "        print(\"\\n🔄 Retrying failed downloads...\")\n",
    "        retry_successful = []\n",
    "        still_failed = []\n",
    "        \n",
    "        for url in failed:\n",
    "            result = downloader.download_audio(url, max_retries=2)\n",
    "            if result:\n",
    "                retry_successful.append(result)\n",
    "            else:\n",
    "                still_failed.append(url)\n",
    "        \n",
    "        if retry_successful:\n",
    "            print(f\"✓ Successfully downloaded {len(retry_successful)} on retry\")\n",
    "        if still_failed:\n",
    "            print(f\"✗ Still failed: {len(still_failed)} URLs\")\n",
    "            for url in still_failed:\n",
    "                print(f\"  - {url}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== USAGE EXAMPLES ===\n",
      "\n",
      "Example 1: Stream transcribe date range\n",
      "----------------------------------------\n",
      "✓ Loaded API key from: ../.env\n",
      "✓ Found ffmpeg at: /usr/bin/ffmpeg\n",
      "\n",
      "🎵 Streaming transcription: 2024-07-01 to 2024-07-02\n",
      "📁 Transcripts will be saved to: data\n",
      "🧠 Using gemini for transcription\n",
      "\n",
      "[1/2] 2024-07-01\n",
      "🔄 Processing: https://soundcloud.com/radio-ergo/idaacadda-01-jul-2024\n",
      "⬇ Downloading to memory: https://soundcloud.com/radio-ergo/idaacadda-01-jul-2024\n",
      "  🔧 Optimizing audio for transcription...                                \n",
      "  📊 Processing 109.6MB audio in memory\n",
      "  ⚠ Large audio file, processing may take longer\n",
      "  🎯 Generating transcript...\n",
      "  ✓ Transcript saved: IDAACADDA-01-JUL-2024.txt\n",
      "[2/2] 2024-07-02\n",
      "🔄 Processing: https://soundcloud.com/radio-ergo/idaacadda-02-jul-2024\n",
      "⬇ Downloading to memory: https://soundcloud.com/radio-ergo/idaacadda-02-jul-2024\n",
      "  🔧 Optimizing audio for transcription...                                \n",
      "  📊 Processing 108.7MB audio in memory\n",
      "  ⚠ Large audio file, processing may take longer\n",
      "  🎯 Generating transcript...\n",
      "  ✓ Transcript saved: IDAACADDA-02-JUL-2024.txt\n",
      "\n",
      "============================================================\n",
      "🎵 STREAMING TRANSCRIPTION SUMMARY\n",
      "============================================================\n",
      "  📊 Total URLs processed: 2\n",
      "  ✅ Successfully transcribed: 2\n",
      "  ⏭️  Skipped (already done): 0\n",
      "  ❌ Failed: 0\n",
      "  📁 Transcripts saved to: data\n",
      "  💾 Memory-efficient processing: ✓\n",
      "============================================================\n",
      "\n",
      "\n",
      "Example 3: Batch transcribe existing MP3s\n",
      "----------------------------------------\n",
      "✓ Loaded API key from: ../.env\n",
      "✓ Found ffmpeg at: /usr/bin/ffmpeg\n",
      "📁 Found 0 MP3 files to transcribe\n",
      "📝 Batch size: 3 files\n",
      "\n",
      "Example 4: Memory monitoring\n",
      "----------------------------------------\n",
      "Current memory usage: 1344.5 MB\n",
      "🧹 Memory cleanup completed\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Enhanced SoundCloud Downloader with On-the-Fly Transcription\n",
    "Processes audio files in memory without saving to disk, focusing on transcription output only.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import re\n",
    "import subprocess\n",
    "import sys\n",
    "from datetime import datetime, timedelta\n",
    "import yt_dlp\n",
    "import requests\n",
    "import time\n",
    "import hashlib\n",
    "import json\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from typing import Optional, List, Dict, Tuple, Union\n",
    "import io\n",
    "import tempfile\n",
    "from contextlib import contextmanager\n",
    "\n",
    "# Audio processing imports\n",
    "try:\n",
    "    from pydub import AudioSegment\n",
    "    from pydub.utils import which\n",
    "    PYDUB_AVAILABLE = True\n",
    "except ImportError:\n",
    "    PYDUB_AVAILABLE = False\n",
    "    print(\"Warning: pydub not available. Install with: pip install pydub\")\n",
    "\n",
    "# Transcription imports\n",
    "try:\n",
    "    from google import genai\n",
    "    from google.genai import types\n",
    "    GEMINI_AVAILABLE = True\n",
    "except ImportError:\n",
    "    GEMINI_AVAILABLE = False\n",
    "    print(\"Warning: Google Gemini not available. Install with: pip install google-generativeai\")\n",
    "\n",
    "try:\n",
    "    import whisper\n",
    "    WHISPER_AVAILABLE = True\n",
    "except ImportError:\n",
    "    WHISPER_AVAILABLE = False\n",
    "\n",
    "\n",
    "class MemoryAudioProcessor:\n",
    "    \"\"\"Handles audio processing in memory without disk storage.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.max_memory_size = 100 * 1024 * 1024  # 100MB limit\n",
    "    \n",
    "    def normalize_audio_format(self, audio_data: bytes, target_format: str = \"mp3\") -> bytes:\n",
    "        \"\"\"\n",
    "        Convert audio data to specified format in memory.\n",
    "        \n",
    "        Args:\n",
    "            audio_data (bytes): Raw audio data\n",
    "            target_format (str): Target format ('mp3', 'wav', 'flac')\n",
    "            \n",
    "        Returns:\n",
    "            bytes: Converted audio data\n",
    "            \n",
    "        Raises:\n",
    "            RuntimeError: If pydub is not available or conversion fails\n",
    "        \"\"\"\n",
    "        if not PYDUB_AVAILABLE:\n",
    "            raise RuntimeError(\"pydub is required for audio format conversion\")\n",
    "        \n",
    "        try:\n",
    "            # Load audio from bytes\n",
    "            audio_segment = AudioSegment.from_file(io.BytesIO(audio_data))\n",
    "            \n",
    "            # Convert to target format\n",
    "            output_buffer = io.BytesIO()\n",
    "            audio_segment.export(output_buffer, format=target_format)\n",
    "            \n",
    "            return output_buffer.getvalue()\n",
    "            \n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Audio format conversion failed: {e}\")\n",
    "    \n",
    "    def optimize_audio_for_transcription(self, audio_data: bytes) -> bytes:\n",
    "        \"\"\"\n",
    "        Optimize audio data for better transcription accuracy.\n",
    "        \n",
    "        Args:\n",
    "            audio_data (bytes): Raw audio data\n",
    "            \n",
    "        Returns:\n",
    "            bytes: Optimized audio data\n",
    "        \"\"\"\n",
    "        if not PYDUB_AVAILABLE:\n",
    "            return audio_data  # Return as-is if pydub not available\n",
    "        \n",
    "        try:\n",
    "            # Load audio\n",
    "            audio = AudioSegment.from_file(io.BytesIO(audio_data))\n",
    "            \n",
    "            # Normalize audio for better transcription\n",
    "            # Convert to mono if stereo\n",
    "            if audio.channels > 1:\n",
    "                audio = audio.set_channels(1)\n",
    "            \n",
    "            # Normalize sample rate to 16kHz (good for speech)\n",
    "            if audio.frame_rate != 16000:\n",
    "                audio = audio.set_frame_rate(16000)\n",
    "            \n",
    "            # Normalize volume\n",
    "            audio = audio.normalize()\n",
    "            \n",
    "            # Export optimized audio\n",
    "            output_buffer = io.BytesIO()\n",
    "            audio.export(output_buffer, format=\"wav\")\n",
    "            \n",
    "            return output_buffer.getvalue()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Audio optimization failed: {e}\")\n",
    "            return audio_data  # Return original if optimization fails\n",
    "\n",
    "\n",
    "class TranscriptionEngine:\n",
    "    \"\"\"Handles different transcription methods.\"\"\"\n",
    "    \n",
    "    def __init__(self, method: str = \"gemini\"):\n",
    "        \"\"\"\n",
    "        Initialize transcription engine.\n",
    "        \n",
    "        Args:\n",
    "            method (str): Transcription method ('gemini', 'whisper')\n",
    "        \"\"\"\n",
    "        self.method = method\n",
    "        self.client = None\n",
    "        \n",
    "        # Load environment variables first\n",
    "        self._load_environment()\n",
    "        \n",
    "        if method == \"gemini\":\n",
    "            self._setup_gemini()\n",
    "        elif method == \"whisper\":\n",
    "            self._setup_whisper()\n",
    "    \n",
    "    def _load_environment(self):\n",
    "        \"\"\"Load environment variables from .env file.\"\"\"\n",
    "        from dotenv import load_dotenv\n",
    "        \n",
    "        # Try different possible locations for .env file\n",
    "        possible_env_paths = [\n",
    "            \".env\",  # Current directory\n",
    "            \"../.env\",  # One level up (for notebooks)\n",
    "            \"../../.env\",  # Two levels up\n",
    "            \"/teamspace/studios/this_studio/.env\",  # Your specific path\n",
    "            \"/teamspace/studios/this_studio/somali-radios-with-ai-for-food-security/.env\",  # Project root\n",
    "        ]\n",
    "        \n",
    "        env_loaded = False\n",
    "        for env_path in possible_env_paths:\n",
    "            if os.path.exists(env_path):\n",
    "                try:\n",
    "                    load_dotenv(dotenv_path=env_path)\n",
    "                    api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "                    if api_key:\n",
    "                        print(f\"✓ Loaded API key from: {env_path}\")\n",
    "                        env_loaded = True\n",
    "                        break\n",
    "                except Exception as e:\n",
    "                    print(f\"Warning: Error loading {env_path}: {e}\")\n",
    "        \n",
    "        if not env_loaded:\n",
    "            print(\"Warning: No .env file found with valid GEMINI_API_KEY\")\n",
    "    \n",
    "    def _setup_gemini(self):\n",
    "        \"\"\"Setup Gemini API client.\"\"\"\n",
    "        if not GEMINI_AVAILABLE:\n",
    "            raise RuntimeError(\"Gemini API not available. Install google-generativeai\")\n",
    "        \n",
    "        api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "        if not api_key:\n",
    "            print(\"\\nERROR: GEMINI_API_KEY not found!\")\n",
    "            print(\"Quick fix:\")\n",
    "            print(\"1. Get API key from: https://aistudio.google.com\")\n",
    "            print(\"2. Create .env file in project root:\")\n",
    "            print('   echo \\'GEMINI_API_KEY=\"your_key_here\"\\' > .env')\n",
    "            print(\"3. Or set environment variable:\")\n",
    "            print('   export GEMINI_API_KEY=\"your_key_here\"')\n",
    "            raise EnvironmentError(\"GEMINI_API_KEY not found in environment variables\")\n",
    "        \n",
    "        self.client = genai.Client(api_key=api_key)\n",
    "    \n",
    "    def _setup_whisper(self):\n",
    "        \"\"\"Setup Whisper model.\"\"\"\n",
    "        if not WHISPER_AVAILABLE:\n",
    "            raise RuntimeError(\"Whisper not available. Install with: pip install openai-whisper\")\n",
    "        \n",
    "        try:\n",
    "            self.client = whisper.load_model(\"base\")\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Failed to load Whisper model: {e}\")\n",
    "    \n",
    "    def transcribe_from_memory(\n",
    "        self, \n",
    "        audio_data: bytes, \n",
    "        model: str = \"gemini-2.0-flash\"\n",
    "    ) -> str:\n",
    "        \"\"\"\n",
    "        Transcribe audio data from memory.\n",
    "        \n",
    "        Args:\n",
    "            audio_data (bytes): Audio data in memory\n",
    "            model (str): Model to use for transcription\n",
    "            \n",
    "        Returns:\n",
    "            str: Transcribed text\n",
    "            \n",
    "        Raises:\n",
    "            ValueError: If transcription fails or returns empty result\n",
    "        \"\"\"\n",
    "        if self.method == \"gemini\":\n",
    "            return self._transcribe_gemini(audio_data, model)\n",
    "        elif self.method == \"whisper\":\n",
    "            return self._transcribe_whisper(audio_data)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported transcription method: {self.method}\")\n",
    "    \n",
    "    def _transcribe_gemini(self, audio_data: bytes, model: str) -> str:\n",
    "        \"\"\"Transcribe using Gemini API.\"\"\"\n",
    "        try:\n",
    "            # Create audio part from bytes\n",
    "            audio_part = types.Part.from_bytes(\n",
    "                data=audio_data,\n",
    "                mime_type=\"audio/mp3\"\n",
    "            )\n",
    "            \n",
    "            # Generate transcript\n",
    "            response = self.client.models.generate_content(\n",
    "                model=model,\n",
    "                contents=[\"Generate a transcript of the speech.\", audio_part]\n",
    "            )\n",
    "            \n",
    "            if hasattr(response, 'text') and response.text:\n",
    "                return response.text\n",
    "            else:\n",
    "                raise ValueError(\"No transcript text returned from Gemini API\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"Gemini transcription failed: {e}\")\n",
    "    \n",
    "    def _transcribe_whisper(self, audio_data: bytes) -> str:\n",
    "        \"\"\"Transcribe using Whisper.\"\"\"\n",
    "        try:\n",
    "            # Whisper requires a file, so we use a temporary file\n",
    "            with tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False) as tmp_file:\n",
    "                tmp_file.write(audio_data)\n",
    "                tmp_file_path = tmp_file.name\n",
    "            \n",
    "            try:\n",
    "                result = self.client.transcribe(tmp_file_path)\n",
    "                return result[\"text\"]\n",
    "            finally:\n",
    "                # Clean up temporary file\n",
    "                os.unlink(tmp_file_path)\n",
    "                \n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"Whisper transcription failed: {e}\")\n",
    "\n",
    "\n",
    "class StreamingSoundCloudDownloader:\n",
    "    \"\"\"Enhanced SoundCloud downloader with on-the-fly transcription capabilities.\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        output_dir: str = \"transcriptions\",\n",
    "        transcription_method: str = \"gemini\",\n",
    "        keep_failed_audio: bool = False\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize the streaming downloader.\n",
    "        \n",
    "        Args:\n",
    "            output_dir (str): Directory for transcription files\n",
    "            transcription_method (str): Method for transcription ('gemini', 'whisper')\n",
    "            keep_failed_audio (bool): Whether to save audio files that fail transcription\n",
    "        \"\"\"\n",
    "        self.output_dir = output_dir\n",
    "        self.transcription_method = transcription_method\n",
    "        self.keep_failed_audio = keep_failed_audio\n",
    "        self.ffmpeg_path = None\n",
    "        self.transcription_log = {}\n",
    "        self.log_file = os.path.join(output_dir, \".transcription_log.json\")\n",
    "        \n",
    "        # Initialize components\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        self.audio_processor = MemoryAudioProcessor()\n",
    "        self.transcription_engine = TranscriptionEngine(transcription_method)\n",
    "        \n",
    "        # Load transcription log\n",
    "        self.load_transcription_log()\n",
    "        \n",
    "        # Setup ffmpeg\n",
    "        self.setup_ffmpeg()\n",
    "    \n",
    "    def load_transcription_log(self):\n",
    "        \"\"\"Load the transcription log from file.\"\"\"\n",
    "        if os.path.exists(self.log_file):\n",
    "            try:\n",
    "                with open(self.log_file, 'r') as f:\n",
    "                    self.transcription_log = json.load(f)\n",
    "            except:\n",
    "                self.transcription_log = {}\n",
    "    \n",
    "    def save_transcription_log(self):\n",
    "        \"\"\"Save the transcription log to file.\"\"\"\n",
    "        try:\n",
    "            with open(self.log_file, 'w') as f:\n",
    "                json.dump(self.transcription_log, f, indent=2)\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Could not save transcription log: {e}\")\n",
    "    \n",
    "    def setup_ffmpeg(self):\n",
    "        \"\"\"Setup ffmpeg for audio processing.\"\"\"\n",
    "        self.ffmpeg_path = shutil.which('ffmpeg')\n",
    "        if not self.ffmpeg_path:\n",
    "            # Try common locations\n",
    "            common_locations = [\n",
    "                '/usr/bin/ffmpeg',\n",
    "                '/usr/local/bin/ffmpeg',\n",
    "                '/opt/homebrew/bin/ffmpeg',\n",
    "            ]\n",
    "            \n",
    "            for location in common_locations:\n",
    "                if os.path.exists(location) and os.access(location, os.X_OK):\n",
    "                    self.ffmpeg_path = location\n",
    "                    break\n",
    "        \n",
    "        if self.ffmpeg_path:\n",
    "            print(f\"✓ Found ffmpeg at: {self.ffmpeg_path}\")\n",
    "        else:\n",
    "            print(\"⚠ ffmpeg not found. Some audio processing may fail.\")\n",
    "    \n",
    "    @contextmanager\n",
    "    def memory_buffer_manager(self):\n",
    "        \"\"\"Context manager for handling memory buffers safely.\"\"\"\n",
    "        buffer = io.BytesIO()\n",
    "        try:\n",
    "            yield buffer\n",
    "        finally:\n",
    "            buffer.close()\n",
    "    \n",
    "    def download_to_memory(self, url: str) -> Optional[bytes]:\n",
    "        \"\"\"\n",
    "        Download audio from URL directly to memory buffer.\n",
    "        \n",
    "        Args:\n",
    "            url (str): SoundCloud URL to download\n",
    "            \n",
    "        Returns:\n",
    "            Optional[bytes]: Audio data in memory, None if failed\n",
    "        \"\"\"\n",
    "        print(f\"⬇ Downloading to memory: {url}\")\n",
    "        \n",
    "        with self.memory_buffer_manager() as buffer:\n",
    "            # Custom hook to capture data in memory\n",
    "            def progress_hook(d):\n",
    "                if d['status'] == 'downloading':\n",
    "                    # Write chunks to buffer as they come in\n",
    "                    if 'tmpfilename' in d:\n",
    "                        try:\n",
    "                            with open(d['tmpfilename'], 'rb') as tmp_f:\n",
    "                                chunk = tmp_f.read()\n",
    "                                if chunk:\n",
    "                                    buffer.seek(0)\n",
    "                                    buffer.write(chunk)\n",
    "                        except:\n",
    "                            pass\n",
    "            \n",
    "            # Configure yt-dlp for memory download\n",
    "            ydl_opts = {\n",
    "                'format': 'bestaudio/best',\n",
    "                'noplaylist': True,\n",
    "                'quiet': True,\n",
    "                'no_warnings': True,\n",
    "                'progress_hooks': [progress_hook],\n",
    "                'postprocessors': [{\n",
    "                    'key': 'FFmpegExtractAudio',\n",
    "                    'preferredcodec': 'mp3',\n",
    "                    'preferredquality': '192',\n",
    "                }],\n",
    "            }\n",
    "            \n",
    "            if self.ffmpeg_path:\n",
    "                ffmpeg_dir = os.path.dirname(self.ffmpeg_path)\n",
    "                ydl_opts['ffmpeg_location'] = ffmpeg_dir\n",
    "            \n",
    "            try:\n",
    "                # Use temporary file that we'll read and delete immediately\n",
    "                with tempfile.NamedTemporaryFile(suffix=\".mp3\", delete=False) as tmp_file:\n",
    "                    ydl_opts['outtmpl'] = tmp_file.name.replace('.mp3', '.%(ext)s')\n",
    "                    \n",
    "                    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "                        ydl.download([url])\n",
    "                    \n",
    "                    # Read the processed file into memory\n",
    "                    processed_file = tmp_file.name.replace('.mp3', '.mp3')\n",
    "                    if os.path.exists(processed_file):\n",
    "                        with open(processed_file, 'rb') as f:\n",
    "                            audio_data = f.read()\n",
    "                        \n",
    "                        # Clean up temporary file immediately\n",
    "                        os.unlink(processed_file)\n",
    "                        return audio_data\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"  ✗ Download failed: {str(e)[:100]}\")\n",
    "                return None\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def transcribe_audio_data(\n",
    "        self, \n",
    "        audio_data: bytes, \n",
    "        optimize: bool = True\n",
    "    ) -> Optional[str]:\n",
    "        \"\"\"\n",
    "        Transcribe audio data from memory buffer.\n",
    "        \n",
    "        Args:\n",
    "            audio_data (bytes): Raw audio data\n",
    "            optimize (bool): Whether to optimize audio for transcription\n",
    "            \n",
    "        Returns:\n",
    "            Optional[str]: Transcribed text, None if failed\n",
    "            \n",
    "        Raises:\n",
    "            ValueError: If audio data is invalid or transcription fails\n",
    "        \"\"\"\n",
    "        if not audio_data or len(audio_data) < 1000:\n",
    "            raise ValueError(\"Audio data is too small or empty\")\n",
    "        \n",
    "        try:\n",
    "            # Optimize audio if requested\n",
    "            if optimize and PYDUB_AVAILABLE:\n",
    "                print(\"  🔧 Optimizing audio for transcription...\")\n",
    "                audio_data = self.audio_processor.optimize_audio_for_transcription(audio_data)\n",
    "            \n",
    "            # Check memory usage\n",
    "            memory_mb = len(audio_data) / (1024 * 1024)\n",
    "            print(f\"  📊 Processing {memory_mb:.1f}MB audio in memory\")\n",
    "            \n",
    "            if memory_mb > 100:\n",
    "                print(\"  ⚠ Large audio file, processing may take longer\")\n",
    "            \n",
    "            # Transcribe\n",
    "            print(\"  🎯 Generating transcript...\")\n",
    "            transcript = self.transcription_engine.transcribe_from_memory(audio_data)\n",
    "            \n",
    "            return transcript\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  ✗ Transcription error: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def process_url_streaming(\n",
    "        self, \n",
    "        url: str, \n",
    "        custom_filename: Optional[str] = None\n",
    "    ) -> Tuple[bool, Optional[str]]:\n",
    "        \"\"\"\n",
    "        Complete streaming workflow: download → transcribe → save text.\n",
    "        \n",
    "        Args:\n",
    "            url (str): SoundCloud URL to process\n",
    "            custom_filename (str, optional): Custom name for output file\n",
    "            \n",
    "        Returns:\n",
    "            Tuple[bool, Optional[str]]: (success_status, transcript_file_path)\n",
    "        \"\"\"\n",
    "        # Generate URL hash for tracking\n",
    "        url_hash = hashlib.md5(url.encode()).hexdigest()\n",
    "        \n",
    "        # Check if already processed\n",
    "        if url_hash in self.transcription_log:\n",
    "            existing_file = self.transcription_log[url_hash].get('transcript_path')\n",
    "            if existing_file and os.path.exists(existing_file):\n",
    "                print(f\"✓ Already transcribed: {os.path.basename(existing_file)}\")\n",
    "                return True, existing_file\n",
    "        \n",
    "        print(f\"🔄 Processing: {url}\")\n",
    "        \n",
    "        # Step 1: Download to memory\n",
    "        audio_data = self.download_to_memory(url)\n",
    "        if not audio_data:\n",
    "            return False, None\n",
    "        \n",
    "        try:\n",
    "            # Step 2: Transcribe from memory\n",
    "            transcript = self.transcribe_audio_data(audio_data)\n",
    "            if not transcript:\n",
    "                return False, None\n",
    "            \n",
    "            # Step 3: Save transcript\n",
    "            if custom_filename:\n",
    "                base_filename = custom_filename\n",
    "            else:\n",
    "                # Extract title from URL or use timestamp\n",
    "                base_filename = self.extract_title_from_url(url)\n",
    "            \n",
    "            # Ensure clean filename\n",
    "            safe_filename = re.sub(r'[^\\w\\s-]', '', base_filename)\n",
    "            safe_filename = re.sub(r'[-\\s]+', '-', safe_filename).strip('-')\n",
    "            \n",
    "            transcript_file = os.path.join(self.output_dir, f\"{safe_filename}.txt\")\n",
    "            \n",
    "            # Handle filename conflicts\n",
    "            counter = 1\n",
    "            original_path = transcript_file\n",
    "            while os.path.exists(transcript_file):\n",
    "                name_part = original_path.replace('.txt', '')\n",
    "                transcript_file = f\"{name_part}_{counter}.txt\"\n",
    "                counter += 1\n",
    "            \n",
    "            # Save transcript\n",
    "            with open(transcript_file, 'w', encoding='utf-8') as f:\n",
    "                f.write(f\"# Transcript\\n\")\n",
    "                f.write(f\"**Source**: {url}\\n\")\n",
    "                f.write(f\"**Date**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "                f.write(f\"**Method**: {self.transcription_method}\\n\\n\")\n",
    "                f.write(\"---\\n\\n\")\n",
    "                f.write(transcript)\n",
    "            \n",
    "            # Update log\n",
    "            self.transcription_log[url_hash] = {\n",
    "                'url': url,\n",
    "                'transcript_path': transcript_file,\n",
    "                'processing_date': datetime.now().isoformat(),\n",
    "                'method': self.transcription_method,\n",
    "                'file_size_mb': len(audio_data) / (1024 * 1024)\n",
    "            }\n",
    "            self.save_transcription_log()\n",
    "            \n",
    "            print(f\"  ✓ Transcript saved: {os.path.basename(transcript_file)}\")\n",
    "            return True, transcript_file\n",
    "            \n",
    "        finally:\n",
    "            # Memory cleanup\n",
    "            del audio_data  # Explicit cleanup\n",
    "            \n",
    "    def extract_title_from_url(self, url: str) -> str:\n",
    "        \"\"\"Extract a reasonable title from SoundCloud URL.\"\"\"\n",
    "        try:\n",
    "            # Try to get title from yt-dlp info\n",
    "            ydl_opts = {'quiet': True, 'no_warnings': True}\n",
    "            with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "                info = ydl.extract_info(url, download=False)\n",
    "                if 'title' in info:\n",
    "                    return info['title']\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # Fallback: extract from URL\n",
    "        parts = url.split('/')\n",
    "        if len(parts) >= 2:\n",
    "            return f\"{parts[-2]}_{parts[-1]}\"\n",
    "        \n",
    "        # Final fallback\n",
    "        return f\"soundcloud_audio_{int(time.time())}\"\n",
    "    \n",
    "    def process_date_range_streaming(\n",
    "        self,\n",
    "        profile_url: str,\n",
    "        start_date: Union[str, datetime],\n",
    "        end_date: Union[str, datetime],\n",
    "        batch_size: int = 5\n",
    "    ) -> Dict[str, List[str]]:\n",
    "        \"\"\"\n",
    "        Process date range with streaming transcription.\n",
    "        \n",
    "        Args:\n",
    "            profile_url (str): SoundCloud profile URL\n",
    "            start_date: Start date for range\n",
    "            end_date: End date for range\n",
    "            batch_size (int): Number of files to process before memory cleanup\n",
    "            \n",
    "        Returns:\n",
    "            Dict[str, List[str]]: Results categorized by success/failure\n",
    "        \"\"\"\n",
    "        # Parse dates if strings\n",
    "        if isinstance(start_date, str):\n",
    "            start_date = datetime.strptime(start_date, '%Y-%m-%d')\n",
    "        if isinstance(end_date, str):\n",
    "            end_date = datetime.strptime(end_date, '%Y-%m-%d')\n",
    "        \n",
    "        print(f\"\\n🎵 Streaming transcription: {start_date.date()} to {end_date.date()}\")\n",
    "        print(f\"📁 Transcripts will be saved to: {self.output_dir}\")\n",
    "        print(f\"🧠 Using {self.transcription_method} for transcription\\n\")\n",
    "        \n",
    "        # Generate URLs\n",
    "        urls = self.generate_urls_for_range(profile_url, start_date, end_date)\n",
    "        \n",
    "        if not urls:\n",
    "            print(\"No URLs generated for date range\")\n",
    "            return {'successful': [], 'failed': [], 'skipped': []}\n",
    "        \n",
    "        results = {'successful': [], 'failed': [], 'skipped': []}\n",
    "        batch_count = 0\n",
    "        \n",
    "        for i, (date, url) in enumerate(urls, 1):\n",
    "            print(f\"[{i}/{len(urls)}] {date.date()}\")\n",
    "            \n",
    "            try:\n",
    "                success, transcript_path = self.process_url_streaming(url)\n",
    "                \n",
    "                if success and transcript_path:\n",
    "                    results['successful'].append(transcript_path)\n",
    "                else:\n",
    "                    results['failed'].append(url)\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"  ✗ Processing error: {e}\")\n",
    "                results['failed'].append(url)\n",
    "            \n",
    "            # Memory management: cleanup every batch_size items\n",
    "            batch_count += 1\n",
    "            if batch_count >= batch_size:\n",
    "                print(f\"  🧹 Memory cleanup after {batch_size} items...\")\n",
    "                import gc\n",
    "                gc.collect()\n",
    "                batch_count = 0\n",
    "            \n",
    "            # Rate limiting\n",
    "            time.sleep(2)\n",
    "        \n",
    "        # Print final summary\n",
    "        self.print_processing_summary(results, len(urls))\n",
    "        return results\n",
    "    \n",
    "    def generate_urls_for_range(\n",
    "        self, \n",
    "        profile_url: str, \n",
    "        start_date: datetime, \n",
    "        end_date: datetime\n",
    "    ) -> List[Tuple[datetime, str]]:\n",
    "        \"\"\"Generate potential URLs for a date range.\"\"\"\n",
    "        urls = []\n",
    "        profile_url = profile_url.rstrip('/')\n",
    "        \n",
    "        current_date = start_date\n",
    "        while current_date <= end_date:\n",
    "            day = current_date.day\n",
    "            month = current_date.strftime('%b').lower()\n",
    "            year = current_date.year\n",
    "            \n",
    "            # Generate URL (using your existing pattern)\n",
    "            url = f\"{profile_url}/idaacadda-{day:02d}-{month}-{year}\"\n",
    "            urls.append((current_date, url))\n",
    "            \n",
    "            current_date += timedelta(days=1)\n",
    "        \n",
    "        return urls\n",
    "    \n",
    "    def print_processing_summary(self, results: Dict[str, List[str]], total_urls: int):\n",
    "        \"\"\"Print a summary of processing results.\"\"\"\n",
    "        successful = len(results['successful'])\n",
    "        failed = len(results['failed'])\n",
    "        skipped = len(results['skipped'])\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"🎵 STREAMING TRANSCRIPTION SUMMARY\")\n",
    "        print(f\"{'='*60}\")\n",
    "        print(f\"  📊 Total URLs processed: {total_urls}\")\n",
    "        print(f\"  ✅ Successfully transcribed: {successful}\")\n",
    "        print(f\"  ⏭️  Skipped (already done): {skipped}\")\n",
    "        print(f\"  ❌ Failed: {failed}\")\n",
    "        print(f\"  📁 Transcripts saved to: {self.output_dir}\")\n",
    "        print(f\"  💾 Memory-efficient processing: ✓\")\n",
    "        print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    def validate_url(self, url: str) -> bool:\n",
    "        \"\"\"Validate SoundCloud URL format.\"\"\"\n",
    "        pattern = r'^https?://(?:www\\.)?soundcloud\\.com/[\\w-]+/[\\w-]+'\n",
    "        return bool(re.match(pattern, url))\n",
    "    \n",
    "    def batch_transcribe_existing_files(\n",
    "        self, \n",
    "        audio_dir: str, \n",
    "        batch_size: int = 3\n",
    "    ) -> Dict[str, str]:\n",
    "        \"\"\"\n",
    "        Transcribe existing MP3 files with memory-efficient batch processing.\n",
    "        \n",
    "        Args:\n",
    "            audio_dir (str): Directory containing MP3 files\n",
    "            batch_size (int): Number of files to process before memory cleanup\n",
    "            \n",
    "        Returns:\n",
    "            Dict[str, str]: Processing results per file\n",
    "        \"\"\"\n",
    "        mp3_files = list(Path(audio_dir).glob(\"*.mp3\"))\n",
    "        results = {}\n",
    "        \n",
    "        print(f\"📁 Found {len(mp3_files)} MP3 files to transcribe\")\n",
    "        print(f\"📝 Batch size: {batch_size} files\")\n",
    "        \n",
    "        for i, mp3_file in enumerate(mp3_files, 1):\n",
    "            print(f\"\\n[{i}/{len(mp3_files)}] Processing {mp3_file.name}\")\n",
    "            \n",
    "            try:\n",
    "                # Read file to memory\n",
    "                with open(mp3_file, 'rb') as f:\n",
    "                    audio_data = f.read()\n",
    "                \n",
    "                # Transcribe\n",
    "                transcript = self.transcribe_audio_data(audio_data)\n",
    "                \n",
    "                if transcript:\n",
    "                    # Save transcript\n",
    "                    output_file = os.path.join(\n",
    "                        self.output_dir, \n",
    "                        f\"{mp3_file.stem}.txt\"\n",
    "                    )\n",
    "                    \n",
    "                    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "                        f.write(f\"# Transcript for {mp3_file.name}\\n\")\n",
    "                        f.write(f\"**Date**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\\n\")\n",
    "                        f.write(transcript)\n",
    "                    \n",
    "                    results[mp3_file.name] = \"success\"\n",
    "                    print(f\"  ✓ Saved transcript: {os.path.basename(output_file)}\")\n",
    "                else:\n",
    "                    results[mp3_file.name] = \"failed\"\n",
    "                \n",
    "                # Memory cleanup\n",
    "                del audio_data\n",
    "                \n",
    "                # Batch cleanup\n",
    "                if i % batch_size == 0:\n",
    "                    print(f\"  🧹 Memory cleanup after {batch_size} files...\")\n",
    "                    import gc\n",
    "                    gc.collect()\n",
    "                    time.sleep(1)\n",
    "                    \n",
    "            except Exception as e:\n",
    "                results[mp3_file.name] = f\"error: {e}\"\n",
    "                print(f\"  ✗ Error: {e}\")\n",
    "        \n",
    "        return results\n",
    "\n",
    "\n",
    "# Enhanced usage functions\n",
    "def stream_transcribe_date_range(\n",
    "    profile_url: str,\n",
    "    start_date: str,\n",
    "    end_date: str,\n",
    "    output_dir: str = \"streaming_transcripts\",\n",
    "    method: str = \"gemini\"\n",
    ") -> Dict[str, List[str]]:\n",
    "    \"\"\"\n",
    "    Main function for streaming transcription of date ranges.\n",
    "    \n",
    "    Args:\n",
    "        profile_url (str): SoundCloud profile URL\n",
    "        start_date (str): Start date in 'YYYY-MM-DD' format\n",
    "        end_date (str): End date in 'YYYY-MM-DD' format\n",
    "        output_dir (str): Directory for transcript output\n",
    "        method (str): Transcription method ('gemini' or 'whisper')\n",
    "        \n",
    "    Returns:\n",
    "        Dict[str, List[str]]: Processing results\n",
    "    \"\"\"\n",
    "    downloader = StreamingSoundCloudDownloader(\n",
    "        output_dir=output_dir,\n",
    "        transcription_method=method\n",
    "    )\n",
    "    \n",
    "    return downloader.process_date_range_streaming(\n",
    "        profile_url=profile_url,\n",
    "        start_date=start_date,\n",
    "        end_date=end_date\n",
    "    )\n",
    "\n",
    "def stream_transcribe_single_url(\n",
    "    url: str, \n",
    "    output_dir: str = \"streaming_transcripts\",\n",
    "    method: str = \"gemini\"\n",
    ") -> Tuple[bool, Optional[str]]:\n",
    "    \"\"\"\n",
    "    Transcribe a single URL with streaming processing.\n",
    "    \n",
    "    Args:\n",
    "        url (str): SoundCloud URL to transcribe\n",
    "        output_dir (str): Output directory for transcript\n",
    "        method (str): Transcription method to use\n",
    "        \n",
    "    Returns:\n",
    "        Tuple[bool, Optional[str]]: (success, transcript_file_path)\n",
    "    \"\"\"\n",
    "    downloader = StreamingSoundCloudDownloader(\n",
    "        output_dir=output_dir,\n",
    "        transcription_method=method\n",
    "    )\n",
    "    \n",
    "    return downloader.process_url_streaming(url)\n",
    "\n",
    "def batch_transcribe_existing_mp3s(\n",
    "    input_dir: str,\n",
    "    output_dir: str = \"batch_transcripts\",\n",
    "    method: str = \"gemini\",\n",
    "    batch_size: int = 3\n",
    ") -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Batch transcribe existing MP3 files with memory management.\n",
    "    \n",
    "    Args:\n",
    "        input_dir (str): Directory containing MP3 files\n",
    "        output_dir (str): Directory for transcript output  \n",
    "        method (str): Transcription method to use\n",
    "        batch_size (int): Files to process before memory cleanup\n",
    "        \n",
    "    Returns:\n",
    "        Dict[str, str]: Results per filename\n",
    "    \"\"\"\n",
    "    downloader = StreamingSoundCloudDownloader(\n",
    "        output_dir=output_dir,\n",
    "        transcription_method=method\n",
    "    )\n",
    "    \n",
    "    return downloader.batch_transcribe_existing_files(input_dir, batch_size)\n",
    "\n",
    "# Memory optimization utilities\n",
    "def get_memory_usage() -> float:\n",
    "    \"\"\"\n",
    "    Get current memory usage in MB.\n",
    "    \n",
    "    Returns:\n",
    "        float: Memory usage in megabytes\n",
    "    \"\"\"\n",
    "    import psutil\n",
    "    process = psutil.Process()\n",
    "    memory_mb = process.memory_info().rss / 1024 / 1024\n",
    "    return memory_mb\n",
    "\n",
    "def cleanup_memory():\n",
    "    \"\"\"Force garbage collection and memory cleanup.\"\"\"\n",
    "    import gc\n",
    "    gc.collect()\n",
    "    print(\"🧹 Memory cleanup completed\")\n",
    "\n",
    "\n",
    "# Example usage demonstrations\n",
    "print(\"=== USAGE EXAMPLES ===\\n\")\n",
    "\n",
    "# Example 1: Stream transcribe a date range\n",
    "print(\"Example 1: Stream transcribe date range\")\n",
    "print(\"-\" * 40)\n",
    "example_results = stream_transcribe_date_range(\n",
    "    profile_url=\"https://soundcloud.com/radio-ergo\",\n",
    "    start_date=\"2024-07-01\", \n",
    "    end_date=\"2024-07-02\",\n",
    "    output_dir=\"data\"\n",
    ")\n",
    "\n",
    "# Example 2: Single URL streaming transcription  \n",
    "# print(\"\\nExample 2: Single URL transcription\")\n",
    "# print(\"-\" * 40)\n",
    "# success, transcript_path = stream_transcribe_single_url(\n",
    "#     url=\"https://soundcloud.com/radio-ergo/idaacadda-01-jul-2024\",\n",
    "#     output_dir=\"single_transcripts\"\n",
    "# )\n",
    "\n",
    "# Example 3: Batch process existing files\n",
    "print(\"\\nExample 3: Batch transcribe existing MP3s\")\n",
    "print(\"-\" * 40)\n",
    "batch_results = batch_transcribe_existing_mp3s(\n",
    "    input_dir=\"./data\",  # Your existing MP3 directory\n",
    "    output_dir=\"batch_transcripts\",\n",
    "    batch_size=3\n",
    ")\n",
    "\n",
    "# Example 4: Memory monitoring during processing\n",
    "print(\"\\nExample 4: Memory monitoring\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"Current memory usage: {get_memory_usage():.1f} MB\")\n",
    "cleanup_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
